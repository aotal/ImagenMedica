---
title: "LARGE LANGUAGE MODELS (LLM) APLICADOS AL ENTORNO MÉDICO"
date: "2025-02-10"
categories: [Presentación]
image: img/portada_llm.png
author: "[Antonio Otal Palacín](antonio.otal@udl.cat)"
institute: Hospital Universitari Arnau de Vilanova (Lleida)
lang: es
format: 
    revealjs:
        logo: 'https://cdn0.iconfinder.com/data/icons/modern-ui-glyph-1/64/modern-ui-glyph-1-03-512.png'
        footer-logo-link: "/"
        footer: "[IAMED](https://cv.udl.cat/portal/site/100794-2324/tool/3d5c2c81-a50b-43ce-a0bf-ecbfd152350b)"
        css: styles.css
        number-sections: false
        slide-number: false
        center: false
filters:
  - reveal-header        
jupyter: python3   
---

## Índice

-   Introducción breve a los LLM
-   Embedding Systems
-   Fine-Tuning y Retrieval Augmentation Generation (RAG)
-   Ejemplo de RAG según la estructuración de los datos
-   Knowledge Graphs
-   Límites de los LLM

::: notes
Notes
:::

# Introducción breve a los LLM

::: notes
Notes
:::

## LLM

![](img/llm.gif){fig-align="center"}

::: notes
Notes
:::

## LLM Pretraining

A una velocidad de 1000 millones de operaciones por segundo entrenar a GPT3 nos costaría 100 millones de años.

Se hubiese tenido que empezar a entrenar el modelo en el cretácico.

::: notes
Notes
:::

## LLM Reinforcement Learning with Human Feedback

![](img/pretraining.gif){fig-align="center"}

::: notes
Notes
:::

## LLM GPU

![](img/gpu.gif){fig-align="center"}

::: notes
Notes
:::

## TRANSFORMERS

::::: columns
::: {.column width="20%"}
![](img/transformer.jpg){.absolute top="200left=0" width="200" height="200"} ![](img/qrcode_transformers.png){.absolute top="350" left="0" width="200" height="200"} ![](img/deeplearningai.png){.absolute top="550" left="0" width="200"}
:::

::: {.column width="80%"}
<p style="font-size: 30px;">

**Codificaciones posicionales**: Los transformers agregan un número a cada palabra para indicar su posición en la oración. Esto ayuda al modelo a comprender el orden de las palabras, lo cual es crucial para el significado.

</p>

<p style="font-size: 30px;">

**Atención**: Permite al modelo considerar todas las palabras de la oración al traducir o analizar una palabra específica. Esto ayuda a capturar relaciones complejas entre palabras y mejora la precisión de la traducción y la comprensión.

</p>

<p style="font-size: 30px;">

**Autoatención**: Permite al modelo comprender una palabra en el contexto de las palabras que la rodean, lo que ayuda a desambiguar palabras con múltiples significados y captar matices del lenguaje.

</p>
:::
:::::

::: notes
Notes
:::

# Vector Embedding

## EMBEDDING

<blockquote cite>

*Vector embeddings* son representaciones numéricas de información, como texto, documentos, imágenes o audio. Capturan el significado semántico de la información

</blockquote>

::: notes
Notes
:::

## VECTORES

![](img/vectores.gif)

::: notes
Notes
:::

## EMBEDDING MACHINE

![](img/embeddings.png)

::: notes
Notes
:::

# FINE-TUNNING y RETRIEVAS AUGMENTATION GENERATION (RAG)

## FINE-TUNNING

<blockquote cite>

El ajuste fino de un LLM es una técnica de aprendizaje por transferencia en la que se toma un modelo pre-entrenado con un gran conjunto de datos para una tarea general, y se realizan pequeños ajustes a sus parámetros internos para optimizar su rendimiento en una nueva tarea específica

</blockquote>

::: notes
Notes
:::

## TRANSFER LEARNING

![](img/transferlearning.png)

::: notes
Notes
:::

## FINE-TUNNING (ESQUEMA)

![](img/esquemafinetunning.png)

::: notes
Notes
:::

## FINE-TUNNING (ESQUEMA)

![](img/esquemafinetunning.png)

::: notes
Notes
:::

## FINE-TUNING (DEMOSTRACIÓN)

::::: columns
::: {.column width="30%"}
 ![](img/qr_demo_bio.png){.absolute top="200" left="0" width="300" height="300"}
:::

::: {.column width="70%" .absolute top="240" left="340"}


- BioMistral/BioMistral-7B
- mistralai/Mistral-7B-Instruct-v0.1

[Ejemplo](https://aotal.github.io/CursoAI2024/)
:::
:::::

![](img/huggingface_logo.png){.absolute bottom="100" right="50" width="300"}

::: notes
Notes
:::

## RAG (2020)

- **Vectorización del contenido**: Cada fragmento de texto se convierte en un vector numérico utilizando un modelo de embeddings. Estos vectores representan el significado semántico del texto en un espacio multidimensional.

- **Búsqueda de similitud**: Cuando se realiza una consulta, esta también se vectoriza, y se busca en la base de datos vectorial los fragmentos cuyos vectores sean más cercanos al de la consulta (similaridad coseno, distancia euclidiana, etc.).

::: notes
Notes
:::

## ESQUEMA RAG

![](img/esquemarag.png)

::: notes
Notes
:::

## FINE-TUNNING VS RAG


<div style="display: flex; justify-content: center; align-items: center; height: 75%; margin-top: -60px" >
  <table style="transform: scale(0.75);">
    <tr>
      <th>Característica</th>
      <th>Fine-tuning</th>
      <th>RAG</th>
    </tr>
    <tr>
      <td>Enfoque principal</td>
      <td>Adaptación del modelo</td>
      <td>Aumento de la información</td>
    </tr>
    <tr>
      <td>Método</td>
      <td>Ajuste de parámetros</td>
      <td>Recuperación de información externa</td>
    </tr>
    <tr>
      <td>Ventajas</td>
      <td>Personalización del modelo, eficiencia</td>
      <td>Respuestas contextualmente relevantes, precisión</td>
    </tr>
    <tr>
      <td>Limitaciones</td>
      <td>Dificultad con datos cambiantes, adaptación de estilo limitada</td>
      <td>Adaptación de estilo limitada, enfoque en recuperación</td>
    </tr>
  </table>
</div>

::: notes
Notes
:::

## FINE-TUNNING VS RAG

::: {layout="[15,-5,12]"}
![Finne-tunning](img/medico_fine_tunning.jpg)

![RAG](img/lector_rag.jpg)
:::

::: notes
Notes
:::

# KNOWLEDGE GRAPH

## Lord os the rings

```{=html}
<iframe width="780" height="500" src="https://alon-cohen-gordon.wixsite.com/lotr-graph" title="Lord of the rings"></iframe>
```


## Prueba

```{=html}
<iframe width="1000" height="800" src="html/1_CrearJSON_medicamentos/1_CrearJSON_medicamentos.html" title="CrearJSON"></iframe>
```